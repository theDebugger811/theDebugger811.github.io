<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }

    h1 {
        font-weight:300;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    tr.spaceUnder>td {
        padding-bottom: 10px;
    }
    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                15px 15px 0 0px #fff, /* The fourth layer */
                15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                20px 20px 0 0px #fff, /* The fifth layer */
                20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                25px 25px 0 0px #fff, /* The fifth layer */
                25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        border: 0;
        height: 1.5px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
  <head>
        <title>Interpretable Social Anchors for Human Trajectory Forecasting in Crowds</title>
        <meta property="og:title" content="sceneflow" />
        <!-- <meta property="og:url" content="https://www.youtube.com/watch?v=cYHQKtBLI3Q" /> -->
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:42px">It Is Not the Journey but the Destination: <br> Endpoint Conditioned Trajectory Prediction </span>


    <!-- </center> -->
    
    <br>
    <br>
      <table align=center width=800px>

     <tr>
       <span style="font-size:22px"><a href="https://thedebugger811.github.io/">Parth Kothari</a></span><sup>1</sup>,&nbsp;&nbsp;
      <span style="font-size:22px">Brian Sifringer</span><sup>1</sup>,&nbsp;&nbsp;
      <span style="font-size:22px">Alexandre Alahi</span><sup>1</sup>,&nbsp;&nbsp;
   </tr>


     <tr>
       <td align=center colspan="2" style="font-size:22px">
       <center>
       <sup>1</sup>VITA Lab, EPFL
       </center>
       </td>
      </tr>
    </table>

        <br> <br>
    <table align=center width=700px>
       <tr>
        <td align=center width=100px>
        <center>
        <span style="font-size:28px">CVPR 2021 <span style="color:red">(Poster)</span></span>
        </center>
        </td>
     </tr>
    </table>
         <table align=center width=900>
          <tr>
                <br><br>
                 <span style="font-size:28px">
                <a href="">[Paper]</a> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
                <a href="">[Bibtex]</a> &nbsp; &nbsp; &nbsp; &nbsp;  
                 <a href="">[Github]</a> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;

              </span>
              <br>
              <br>
              <br>
              <br>
              <center><h1>Overview Video</h1></center>
              <iframe width="900" height="660" src="https://www.youtube.com/embed/XCWCHwGlBgE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            <!-- [hosted on <a href="#">arXiv</a>]</a> -->
              </td>
        </tr>
      </table>
            <!--
            <br>
            <table align=center width=600px>
                <tr>
                    <td width=700px>
                      <center>
                          <img src = "teaser.jpg" height="180px"></img><br>
                    </center>
                    </td>
                </tr>
                <tr>
                  <td colspan="3"> <br>
                In the first image, can you predict what the human is going to do next? Depending on his intention, the person can choose to turn left to climb up stairs; he may also go straight through the hallway or turn right to fetch some items off the table. In this work, we propose a method to generate long-term stochastic predictions of future 3D human motion, while also considering the scene context.
    Given one single RGB image and 2D human pose history, our method first generates multiple possible future 2D destinations, then predicts future 3D human paths towards each destination, as shown in the middle, and finally generates 3D human pose sequences following the path, shown in the ground-truth 3D point cloud of the scene in the right. We train our model on both real-world data with noisy ground-truth and our newly-created large-scale synthetic data with diverse scenes, characters, and motions. Both quantitative comparisons and qualitative results demonstrate that our method can generate plausible scene-adaptive predictions.
                  </td>
                </tr>
            </table>
          <hr> -->
<!--           <br>
          <br> -->
<!--           <center>
            <table align=center width=700>
                <tr>
              
                  <td><video width="700px" controls> <source src="hmp.m4v" type=video/mp4><video></td>
              
              </tr>
            </table>
          </center> -->
          
          <br>

          <!-- <hr> -->
          <center><h1>Abstract</h1></center>
          <table align=center width=1000px>
              <tr>
                  <td width=1000px>
<!--                     <center>
                        <img src = "teaser.jpg" height="500px"></img><br>
                  </center> -->
                  <br>
                  <span style="font-size:20px"> Human trajectory forecasting in crowds, at its core, is a sequence prediction problem with specific challenges of capturing inter-sequence dependencies (social interactions) and consequently predicting socially-compliant multimodal distributions. In recent years, neural network-based methods have been shown to outperform hand-crafted methods on distance-based metrics. However, these data-driven methods still suffer from one crucial limitation: lack of interpretability. To overcome this limitation, we leverage the power of discrete choice models to learn interpretable rule-based intents, and subsequently utilise the expressibility of neural networks to model scene-specific residual. Extensive experimentation on the interaction-centric benchmark TrajNet++ demonstrates the effectiveness of our proposed architecture to explain its predictions without compromising the accuracy.
                      </td>
              </tr>

              <tr>
                <td colspan="3"> <br>

                </td>
              </tr>
          </table>


          <hr>
          <center><h1>Key Ideas</h1></center>
          <table align=center width=600px>
              <tr>
                  <td width=700px>
                    <center>
                        <img src = "pull1.pdf" height="500px"></img><br>
                  </center>
                  <br>
                  <span style="font-size:18px"> While navigating in crowds, humans display various social phenomena like collision avoidance (from red trajectory) and leader follower (towards blue trajectory). We present a model that not only outputs accurate future trajectories but also provides a high-level rationale behind its predictions, owing to the interpretability of discrete choice models. (Un)favourable anchors shown in green (red).
                  </td>
              </tr>
<!-- 
We posit that pedestrians in the scene move towards a predetermined position and interactions such as social cues happen as they go along achieving this intention without changing the predilection while still shaping their trajectories locally. 
               -->
              <tr>
                <td colspan="3"> <br>

                </td>
              </tr>
          </table>


        <hr>
         <!-- <table align=center width=550px> -->
                <center><h1>Results</h1></center>
                <table align=center width=900px>
                    <tr>
                        <td width=1200px colspan="3">
                          <center>
                              <img src = "viz_combined4.png" height="540px"></img><br>
                        </center>
                        </td>
                    </tr>
<!--                     <tr>
                      <td align=center width=400px>
                        (a)
                      </td>
                      <td align=center width=400px>
                        (b)
                      </td>
                      <td align=center width=400px>
                        (c)
                      </td>
                  </tr> -->

                    <tr>
                        <td width=600px colspan="3">
                                            <br>
                              <span style="font-size:18px"> Qualitative illustration of the ability of our architecture to output high-level interpretable intents. The direction of motion of the pedestrian of interest is normalized and is facing towards the right. Current neighbour positions are shown in blue and current velocities are shown in green. The ground-truth choice is highlighted in light green. (a) In the first row, the decision of the network is strongly influenced by the collision-avoidance and occupancy map of the DCM.  Consequently, the pedestrian changes the direction of motion and turns left maintaining constant speed. (b) In the second row, the leader-follower map exerts a strong influence on the final decision-making causing the model to choose the anchor corresponding to slowing-down. (c) In the third row, the leader-follower map is not strong in intensity and the neural network map guides the decision making resulting in the model maintaining constant speed.
                                  </td>
                    </tr>
                </table>
                <br>
      

    <hr>
      <table align=center width=900>
       <center><h1>Paper</h1></center>
          <tr>
            <td><a href="https://arxiv.org/pdf/2004.02025.pdf"><img align=center style="width:400px" src="paper_collage.png"/></a></td>
            <td><span style="font-size:14pt">P. Kothari, B. Sifringer, A. Alahi. <br><br>
              Interpretable Social Anchors for Human Trajectory Forecasting in Crowds<br><br>
            ECCV 2020  <a href = "http://cvpr2021.thecvf.com"> <b> (Poster) </b> </a><br><br>
                <a href="">[Paper]</a> &nbsp; &nbsp;
                <a href="">[Bibtex]</a> &nbsp; &nbsp;
                <a href="">[Github]</a> 
            <!-- [hosted on <a href="#">arXiv</a>]</a> -->
              </td>
        </tr>
      </table>
    <br>
    <!--
    <hr>
      <center><h1>Code</h1></center>
      <tr>
        <td>
          <span style="font-size:28px">&nbsp;<a href='#'>[GitHub]</a>  (coming soon)
        </td>
      <br>
      -->
      <hr>
            <table align=center width=950px>
                <tr>
                    <td>
                      <left>
                <center><h1>Acknowledgements</h1></center>
                We thank <span style="font-size:14px"><a href="http://www.niebles.net/">Prof. Juan Carlos Niebles</a></span> for helpful advice and suggestions. This webpage template was borrowed from some <a href="https://richzhang.github.io/colorization/">colorful folks</a>.
            </left>
        </td>
        </tr>
        </table>

        <br><br>
</body>
</html>
